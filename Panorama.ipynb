{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62596a62-2686-4445-be81-0045fcff575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.14 (main, May  6 2024, 14:47:20) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dfbb96-8e83-4601-b881-5ac2f93c625a",
   "metadata": {},
   "source": [
    "### streetview: a package that gathers panorama street images given latitude and longitude.\n",
    "- [GitHub Repository](https://github.com/robolyst/streetview)\n",
    "- *Installation:*\n",
    "    ```bash\n",
    "    pip install streetview\n",
    "    ```\n",
    "### `streetview.search_panoramas()`\n",
    "\n",
    "- *Input:*\n",
    "    1. ***latitude***\n",
    "    2. ***longitude***\n",
    "\n",
    "- *Output:*\n",
    "    *A list of information tuples. The first element, `panos[0]`, returns crucial info:*\n",
    "    1. ***pano_id:*** *a key for each image data in the source pool*\n",
    "    2. ***lat:*** *latitude of the location*\n",
    "    3. ***lon:*** *longitude of the location*\n",
    "    4. ***heading:*** *The compass heading, or the direction the camera is facing, measured in degrees from true north.*\n",
    "    5. ***pitch:*** *The angle at which the camera is tilted up or down.*\n",
    "    6. ***roll:*** *The angle at which the camera is tilted sideways.*\n",
    "    7. ***date:*** *The date when the panorama was captured.*\n",
    "    8. ***Elevation:*** *The elevation of the camera when the panorama was taken. If this is None, it means the elevation information is not provided or not applicable.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc8a882-228a-4bae-b5f8-5402c323bb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pano_id='B5LQCXCjt-ZBgQDVD062Xg' lat=43.156551040182 lon=-77.60884812843123 heading=77.48731231689453 pitch=90.15473175048828 roll=1.819120526313782 date='2015-07' elevation=None\n"
     ]
    }
   ],
   "source": [
    "from streetview import search_panoramas\n",
    "panos = search_panoramas(lat=43.156573, lon=-77.608849)\n",
    "first = panos[0]\n",
    "print(first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50b468-e52d-4e76-b7d6-7f053225aadb",
   "metadata": {},
   "source": [
    "### `streetview.fetch_panorama()`\n",
    "\n",
    "- **Input:**\n",
    "  - ***pano_id:*** *the unique key you obtained using `search_panoramas()`*\n",
    "\n",
    "- **Output:**\n",
    "  - *an image entity, you could use `image.save(dir, format)`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280aaad-c1f7-42f2-b85c-5ce0947df11c",
   "metadata": {},
   "source": [
    "### Monitoring Space and Time Taken\n",
    "\n",
    "To monitor the space and time taken for a request, use the `memory_profiler` and `time` modules.\n",
    "\n",
    "- **Install `memory_profiler`:**\n",
    "\n",
    "  ```bash\n",
    "  pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df84f34a-985f-4882-be3f-a6325b3d6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 100.19 seconds\n",
      "Memory usage: 511.01 MiB\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from memory_profiler import memory_usage\n",
    "from streetview import get_panorama\n",
    "\n",
    "def execute_and_profile():\n",
    "    # Start timing\n",
    "    start_time = time()\n",
    "    \n",
    "    # Function to measure memory usage\n",
    "    def fetch_panorama():\n",
    "        image = get_panorama(pano_id='B5LQCXCjt-ZBgQDVD062Xg')\n",
    "        image.save('/Users/klz/Desktop/Cantay_Panorama/input_pano/example.jpg', \"jpeg\")\n",
    "\n",
    "    mem_usage = memory_usage(fetch_panorama)\n",
    "    end_time = time()\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    return time_taken, mem_usage\n",
    "\n",
    "time_taken, mem_usage = execute_and_profile()\n",
    "\n",
    "print(f\"Time taken: {time_taken:.2f} seconds\")\n",
    "print(f\"Memory usage: {max(mem_usage) - min(mem_usage):.2f} MiB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6dce0a-4a8d-4366-899b-a96ad3003c06",
   "metadata": {},
   "source": [
    "### Converting Panorama Image to Perspective Image\n",
    "\n",
    "Now, we need to convert a panorama image into a perspective image. This process is called **Equirectangular projection**: *Directly maps the longitude to the x-coordinate and latitude to the y-coordinate.*\n",
    "\n",
    "Thanks to: https://github.com/fuenwang/Equirec2Perspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18781345-0a4a-4bce-8735-4f099c4019b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.09 seconds\n",
      "Memory usage: 1137.72 MiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "def xyz2lonlat(xyz):\n",
    "    atan2 = np.arctan2\n",
    "    asin = np.arcsin\n",
    "\n",
    "    norm = np.linalg.norm(xyz, axis=-1, keepdims=True)\n",
    "    xyz_norm = xyz / norm\n",
    "    x = xyz_norm[..., 0:1]\n",
    "    y = xyz_norm[..., 1:2]\n",
    "    z = xyz_norm[..., 2:]\n",
    "\n",
    "    lon = atan2(x, z)\n",
    "    lat = asin(y)\n",
    "    lst = [lon, lat]\n",
    "\n",
    "    out = np.concatenate(lst, axis=-1)\n",
    "    return out\n",
    "\n",
    "def lonlat2XY(lonlat, shape):\n",
    "    X = (lonlat[..., 0:1] / (2 * np.pi) + 0.5) * (shape[1] - 1)\n",
    "    Y = (lonlat[..., 1:] / (np.pi) + 0.5) * (shape[0] - 1)\n",
    "    lst = [X, Y]\n",
    "    out = np.concatenate(lst, axis=-1)\n",
    "\n",
    "    return out \n",
    "\n",
    "class Equirectangular:\n",
    "    def __init__(self, img_name):\n",
    "        self._img = cv2.imread(img_name, cv2.IMREAD_COLOR)\n",
    "        [self._height, self._width, _] = self._img.shape\n",
    "\n",
    "    def GetPerspective(self, FOV, THETA, PHI, height, width):\n",
    "        #\n",
    "        # THETA is left/right angle, PHI is up/down angle, both in degree\n",
    "        #\n",
    "\n",
    "        f = 0.5 * width * 1 / np.tan(0.5 * FOV / 180.0 * np.pi)\n",
    "        cx = (width - 1) / 2.0\n",
    "        cy = (height - 1) / 2.0\n",
    "        K = np.array([\n",
    "                [f, 0, cx],\n",
    "                [0, f, cy],\n",
    "                [0, 0,  1],\n",
    "            ], np.float32)\n",
    "        K_inv = np.linalg.inv(K)\n",
    "        \n",
    "        x = np.arange(width)\n",
    "        y = np.arange(height)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        z = np.ones_like(x)\n",
    "        xyz = np.concatenate([x[..., None], y[..., None], z[..., None]], axis=-1)\n",
    "        xyz = xyz @ K_inv.T\n",
    "\n",
    "        y_axis = np.array([0.0, 1.0, 0.0], np.float32)\n",
    "        x_axis = np.array([1.0, 0.0, 0.0], np.float32)\n",
    "        R1, _ = cv2.Rodrigues(y_axis * np.radians(THETA))\n",
    "        R2, _ = cv2.Rodrigues(np.dot(R1, x_axis) * np.radians(PHI))\n",
    "        R = R2 @ R1\n",
    "        xyz = xyz @ R.T\n",
    "        lonlat = xyz2lonlat(xyz) \n",
    "        XY = lonlat2XY(lonlat, shape=self._img.shape).astype(np.float32)\n",
    "        persp = cv2.remap(self._img, XY[..., 0], XY[..., 1], cv2.INTER_CUBIC, borderMode=cv2.BORDER_WRAP)\n",
    "\n",
    "        return persp\n",
    "\n",
    "def profile_conversion(img_path, save_path, FOV, THETA, PHI, height, width):\n",
    "    def fetch_panorama():\n",
    "        equi = Equirectangular(img_path)\n",
    "        image = equi.GetPerspective(FOV, THETA, PHI, height, width)\n",
    "        cv2.imwrite(save_path, image)\n",
    "    \n",
    "    start_time = time()\n",
    "    mem_usage = memory_usage(fetch_panorama)\n",
    "    end_time = time()\n",
    "    \n",
    "    time_taken = end_time - start_time\n",
    "    memory_taken = max(mem_usage) - min(mem_usage)\n",
    "    \n",
    "    return time_taken, memory_taken\n",
    "\n",
    "# Path to the example image\n",
    "img_path = '/Users/klz/Desktop/Cantay_Panorama/input_pano/example.jpg'\n",
    "save_path = '/Users/klz/Desktop/Cantay_Panorama/output_pers/perspective.jpg'\n",
    "\n",
    "# Parameters for GetPerspective\n",
    "FOV = 120  # Wider field of view to capture more information\n",
    "THETA = 0  # Adjust this to look left or right\n",
    "PHI = 0    # Adjust this to look up or down\n",
    "height = 2000  # Increase height to capture more detail\n",
    "width = 3600   # Increase width to capture more detail\n",
    "time_taken, memory_taken = profile_conversion(img_path, save_path, FOV, THETA, PHI, height, width)\n",
    "\n",
    "print(f\"Time taken: {time_taken:.2f} seconds\")\n",
    "print(f\"Memory usage: {memory_taken:.2f} MiB\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "554f7cf0-230b-40a8-8473-7aa934942308",
   "metadata": {},
   "source": [
    "https://blogs.codingballad.com/unwrapping-the-view-transforming-360-panoramas-into-intuitive-videos-with-python-6009bd5bca94\n",
    "\n",
    "- from 360 panorama to a 360 perspective rotation gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7de6fb-410e-4091-9e1d-fbd87bbf37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from time import time\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "def xyz2lonlat(xyz):\n",
    "    atan2 = np.arctan2\n",
    "    asin = np.arcsin\n",
    "\n",
    "    norm = np.linalg.norm(xyz, axis=-1, keepdims=True)\n",
    "    xyz_norm = xyz / norm\n",
    "    x = xyz_norm[..., 0:1]\n",
    "    y = xyz_norm[..., 1:2]\n",
    "    z = xyz_norm[..., 2:]\n",
    "\n",
    "    lon = atan2(x, z)\n",
    "    lat = asin(y)\n",
    "    lst = [lon, lat]\n",
    "\n",
    "    out = np.concatenate(lst, axis=-1)\n",
    "    return out\n",
    "\n",
    "def lonlat2XY(lonlat, shape):\n",
    "    X = (lonlat[..., 0:1] / (2 * np.pi) + 0.5) * (shape[1] - 1)\n",
    "    Y = (lonlat[..., 1:] / (np.pi) + 0.5) * (shape[0] - 1)\n",
    "    lst = [X, Y]\n",
    "    out = np.concatenate(lst, axis=-1)\n",
    "\n",
    "    return out \n",
    "\n",
    "class Equirectangular:\n",
    "    def __init__(self, img_name):\n",
    "        self._img = cv2.imread(img_name, cv2.IMREAD_COLOR)\n",
    "        [self._height, self._width, _] = self._img.shape\n",
    "\n",
    "    def GetPerspective(self, FOV, THETA, PHI):\n",
    "        height = self._height\n",
    "        width = self._width\n",
    "        f = 0.5 * width / np.tan(0.5 * FOV / 180.0 * np.pi)\n",
    "        cx = (width - 1) / 2.0\n",
    "        cy = (height - 1) / 2.0\n",
    "        K = np.array([\n",
    "                [f, 0, cx],\n",
    "                [0, f, cy],\n",
    "                [0, 0,  1],\n",
    "            ], np.float32)\n",
    "        K_inv = np.linalg.inv(K)\n",
    "        \n",
    "        x = np.arange(width)\n",
    "        y = np.arange(height)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        z = np.ones_like(x)\n",
    "        xyz = np.concatenate([x[..., None], y[..., None], z[..., None]], axis=-1)\n",
    "        xyz = xyz @ K_inv.T\n",
    "\n",
    "        y_axis = np.array([0.0, 1.0, 0.0], np.float32)\n",
    "        x_axis = np.array([1.0, 0.0, 0.0], np.float32)\n",
    "        R1, _ = cv2.Rodrigues(y_axis * np.radians(THETA))\n",
    "        R2, _ = cv2.Rodrigues(np.dot(R1, x_axis) * np.radians(PHI))\n",
    "        R = R2 @ R1\n",
    "        xyz = xyz @ R.T\n",
    "        lonlat = xyz2lonlat(xyz) \n",
    "        XY = lonlat2XY(lonlat, shape=self._img.shape).astype(np.float32)\n",
    "        persp = cv2.remap(self._img, XY[..., 0], XY[..., 1], cv2.INTER_LINEAR, borderMode=cv2.BORDER_WRAP)\n",
    "\n",
    "        return persp\n",
    "\n",
    "def evaluate_image_similarity(original_img, transformed_img):\n",
    "    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    transformed_gray = cv2.cvtColor(transformed_img, cv2.COLOR_BGR2GRAY)\n",
    "    score, _ = ssim(original_gray, transformed_gray, full=True)\n",
    "    return score\n",
    "\n",
    "def find_optimal_params(img_path, save_path):\n",
    "    best_params = None\n",
    "    best_image = None\n",
    "    best_quality = -1\n",
    "    \n",
    "    fov_range = range(60, 121, 10)  # FOV from 60 to 120 degrees\n",
    "    theta_range = range(-90, 91, 30)  # THETA from -90 to 90 degrees\n",
    "    phi_range = range(-45, 46, 15)  # PHI from -45 to 45 degrees\n",
    "    \n",
    "    original_img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    height, width, _ = original_img.shape\n",
    "    \n",
    "    for FOV in fov_range:\n",
    "        for THETA in theta_range:\n",
    "            for PHI in phi_range:\n",
    "                equi = Equirectangular(img_path)\n",
    "                image = equi.GetPerspective(FOV, THETA, PHI)\n",
    "                \n",
    "                quality = evaluate_image_similarity(original_img, image)\n",
    "                \n",
    "                if quality > best_quality:\n",
    "                    best_quality = quality\n",
    "                    best_params = (FOV, THETA, PHI)\n",
    "                    best_image = image\n",
    "    \n",
    "    if best_image is not None:\n",
    "        cv2.imwrite(save_path, best_image)\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# Path to the example image\n",
    "img_path = '/Users/klz/Desktop/Cantay_Panorama/input_pano/example.jpg'\n",
    "save_path = '/Users/klz/Desktop/Cantay_Panorama/output_pers/perspective.jpg'\n",
    "\n",
    "best_params = find_optimal_params(img_path, save_path)\n",
    "\n",
    "print(f\"Optimal parameters: FOV={best_params[0]}, THETA={best_params[1]}, PHI={best_params[2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0cbfe-d33b-4767-81a6-6a05b5a0ab01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
